{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hr6QvWC1sVno"
   },
   "source": [
    "# Pandas 1\n",
    "\n",
    "## Jane Slagle\n",
    "\n",
    "## Math 403 Section 2\n",
    "\n",
    "## 8/29/22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D1pxi6sWEcmJ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y8nzrZCaE4bn"
   },
   "source": [
    "# Problem 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prob 1\n",
    "def prob1(file='budget.csv'):\n",
    "    \"\"\"\"\n",
    "    Read in budget.csv as a DataFrame with the index as column 0 and perform each of these operations on the DataFrame in order. \n",
    "    \n",
    "    1) Reindex the columns such that amount spent on groceries is the first column and all other columns maintain the same ordering.\n",
    "    2) Sort the DataFrame in descending order based on how much money was spent on Groceries.\n",
    "    3) Reset all values in the 'Rent' column to 800.0.\n",
    "    4) Reset all values in the first 5 data points to 0.0\n",
    "    \n",
    "    Return the values of the updated DataFrame as a NumPy array.\n",
    "    \n",
    "    Parameters:\n",
    "        file (str): name of datafile\n",
    "        \n",
    "    Return:\n",
    "        values (ndarray): values of DataFrame\n",
    "    \"\"\"\n",
    "    budget = pd.read_csv(file, index_col = 0) #1st read in csv file, convert into DataFrame using method. set index as column 0\n",
    "    \n",
    "    budget = budget.reindex(columns = ['Groceries','Rent','Utilities','Dining Out','Gas','Out With Friends','Netflix'])\n",
    "    #reorder columns so that Groceries is 1st, keep all others in same ordering\n",
    "\n",
    "    budget = budget.sort_values('Groceries', ascending = False) #sort DataFrame descending according to $$ spent on Groceries\n",
    "    \n",
    "    budget['Rent'] = 800.0 #reset Rent column so that all have 800.0\n",
    "    \n",
    "    #can use iloc to access DataFrame through its indexers and want reset 1st 5 datapoints to be 0.0 & each\n",
    "    budget.iloc[[0,1,2,3,4]] = 0.0 #row is a separate datapoint and each row is an index, so reset 1st 5 rows\n",
    "        \n",
    "    return budget.values #return all values of DataFrame as numpy array\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [174., 800.,  90.,  37.,  30.,  23.,   8.],\n",
       "       [174., 800.,  82.,  35.,  nan,  26.,  nan],\n",
       "       [172., 800.,  82.,  31.,  30.,  26.,   8.],\n",
       "       [171., 800.,  82.,  40.,  nan,  23.,  nan],\n",
       "       [171., 800.,  82.,  35.,  nan,  27.,  nan],\n",
       "       [171., 800.,  80.,  30.,  31.,  22.,  nan],\n",
       "       [170., 800.,  90.,  34.,  33.,  nan,   8.],\n",
       "       [170., 800.,  85.,  34.,  nan,  25.,  nan],\n",
       "       [167., 800.,  92.,  30.,  nan,  29.,  nan],\n",
       "       [163., 800.,  85.,  30.,  nan,  nan,  nan],\n",
       "       [163., 800.,  90.,  31.,  nan,  25.,  nan],\n",
       "       [161., 800.,  85.,  30.,  nan,  24.,  nan],\n",
       "       [160., 800.,  91.,  32.,  28.,  23.,  nan],\n",
       "       [158., 800.,  92.,  nan,  nan,  22.,  nan],\n",
       "       [157., 800.,  82.,  nan,  32.,  21.,   8.],\n",
       "       [155., 800.,  80.,  nan,  33.,  26.,   8.],\n",
       "       [155., 800.,  92.,  33.,  nan,  nan,  nan],\n",
       "       [153., 800.,  80.,  31.,  30.,  27.,   8.],\n",
       "       [152., 800.,  95.,  30.,  46.,  nan,   8.],\n",
       "       [152., 800.,  85.,  39.,  nan,  29.,  nan],\n",
       "       [152., 800.,  95.,  32.,  34.,  22.,   8.],\n",
       "       [150., 800.,  90.,  34.,  nan,  25.,  nan],\n",
       "       [148., 800.,  91.,  40.,  31.,  nan,  nan],\n",
       "       [148., 800.,  91.,  34.,  28.,  27.,  nan],\n",
       "       [146., 800.,  95.,  31.,  32.,  23.,   8.],\n",
       "       [145., 800.,  91.,  30.,  29.,  28.,  nan],\n",
       "       [145., 800.,  82.,  40.,  nan,  27.,  nan],\n",
       "       [145., 800.,  90.,  32.,  nan,  29.,  nan],\n",
       "       [143., 800.,  95.,  38.,  34.,  21.,   8.],\n",
       "       [141., 800.,  82.,  37.,  nan,  27.,  nan],\n",
       "       [140., 800.,  82.,  31.,  30.,  24.,   8.],\n",
       "       [140., 800.,  92.,  34.,  nan,  24.,  nan],\n",
       "       [137., 800.,  82.,  nan,  31.,  28.,   8.],\n",
       "       [137., 800.,  82.,  36.,  nan,  20.,  nan],\n",
       "       [137., 800.,  95.,  36.,  34.,  23.,   8.],\n",
       "       [136., 800.,  92.,  36.,  nan,  22.,  nan],\n",
       "       [135., 800.,  90.,  34.,  32.,  22.,   8.],\n",
       "       [134., 800.,  82.,  39.,  35.,  24.,   8.],\n",
       "       [133., 800.,  91.,  36.,  nan,  23.,  nan],\n",
       "       [131., 800.,  85.,  38.,  nan,  23.,  nan],\n",
       "       [131., 800.,  80.,  31.,  29.,  nan,  nan],\n",
       "       [130., 800.,  85.,  31.,  nan,  22.,  nan],\n",
       "       [130., 800.,  91.,  34.,  nan,  21.,  nan]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test prob 1\n",
    "prob1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FcGE9Qq5scpv"
   },
   "source": [
    "# Problem 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bZIdjL74RuuO"
   },
   "outputs": [],
   "source": [
    "# Prob 2\n",
    "def prob2(file='budget.csv'):\n",
    "    \"\"\"\n",
    "    Read in file as DataFrame.\n",
    "    Fill all NaN values with 0.0.\n",
    "    Create two new columns, 'Living Expenses' and 'Other'. \n",
    "    Sum the columns 'Rent', 'Groceries', 'Gas' and 'Utilities' and set it as the value of 'Living Expenses'.\n",
    "    Sum the columns 'Dining Out', 'Out With Friends' and 'Netflix' and set as the value of 'Other'.\n",
    "    Identify which column, other than 'Living Expenses' correlates most with 'Living Expenses'\n",
    "    and which column other than 'Other' correlates most with 'Other'.\n",
    "\n",
    "    Return the names of each of those columns as a tuple.\n",
    "    The first should be of the column corresponding to \\li{'Living Expenses'} and the second to \\li{'Other'}.\n",
    "    \n",
    "    Parameters:\n",
    "        file (str): name of datafile\n",
    "        \n",
    "    Return:\n",
    "        values (tuple): (name of column that most relates to Living Expenses, name of column that most relates to Other)\n",
    "    \"\"\"\n",
    "    budget = pd.read_csv(file)   #read in csv file as DataFrame\n",
    "    budget = budget.fillna(0.0)  #fill all NaN values w/ 0.0\n",
    "    \n",
    "    #create 2 new columns whose values are made of sum of other columns values\n",
    "    budget['Living Expenses'] = budget['Rent'] + budget['Groceries'] + budget['Gas'] + budget['Utilities']\n",
    "    budget['Other'] = budget['Dining Out'] + budget['Out With Friends'] + budget['Netflix']\n",
    "    \n",
    "    corr = budget.corr() #get the correlation between all of the columns\n",
    "    \n",
    "    #identify which column, other than 'Living Expenses', correlates most with 'LE', same with Other column\n",
    "    \n",
    "    #use loc to select LE, Other columns. matrix symmetric so columns are same as rows \n",
    "    #want column most correlated to them that aren't themselves so will want the 2nd one (it will be 1st one)\n",
    "    LE_corr = corr.loc['Living Expenses'].sort_values(ascending = False).index[1]\n",
    "    other_corr = corr.loc['Other'].sort_values(ascending = False).index[1]\n",
    "    \n",
    "    return (LE_corr, other_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Rent', 'Dining Out')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test prob 2\n",
    "prob2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qVHAwFRRseXh"
   },
   "source": [
    "# Problem 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "35VAshdqZhVD"
   },
   "outputs": [],
   "source": [
    "def prob3(file='crime_data.csv'):\n",
    "    \"\"\"\n",
    "    Read in crime data and use pandas to answer the following questions.\n",
    "    \n",
    "    Set the index as the column 'Year', and return the answers to each question as a tuple.\n",
    "    \n",
    "    1) Identify the three crimes that have a mean over 1,500,000. \n",
    "    Of these three crimes, which two are very correlated? \n",
    "    Which of these two crimes has a greater maximum value?\n",
    "    Save the title of this column as a variable to return as the answer.\n",
    "    \n",
    "    2) Examine the data since 2000.\n",
    "    Sort this data (in ascending order) according to number of murders.\n",
    "    Find the years where Aggravated Assault is greater than 850,000.\n",
    "    Save the indices (the years) of the masked and reordered DataFrame as a NumPy array to return as the answer.\n",
    "    \n",
    "    3) What year had the highest crime rate? \n",
    "    In this year, which crime was committed the most? \n",
    "    What percentage of the total crime that year was it? \n",
    "    Save this value as a float.\n",
    "    \n",
    "    \n",
    "    Parameters:\n",
    "        file (str): data\n",
    "    \n",
    "    Return:\n",
    "        ans_1 (string): answer to Question 1\n",
    "        ans_2 (ndarray): answer to Question 2\n",
    "        ans_3 (float): answer to Question 3\n",
    "    \"\"\"\n",
    "    criminy = pd.read_csv(file, index_col = 'Year') #read file as pandas object, set index as column Year\n",
    "    \n",
    "    #part 1:\n",
    "    #drop population, total columns because only want crime columns\n",
    "    criminy1 = criminy.drop('Population', axis = 1).drop('Total', axis = 1) #put axis there to specify want entire column gone\n",
    "    mask1 = criminy1.mean() > 1500000 #mask to find 3 crimes w/ mean over 1.5 mil\n",
    "    three_crimes = criminy1.columns[mask1] #apply mask to cols bc mask tells you which cols are > 1.5 mil. want 3 cols that are true\n",
    "    corr = criminy1[three_crimes].corr()   #get correlation btw all 3 crimes\n",
    "    \n",
    "    #find which column each of the 3 cols are most correlated with to find the 2 that are most related\n",
    "    val1 = corr.loc[three_crimes[0]].sort_values(ascending = False).index[1]\n",
    "    val2 = corr.loc[three_crimes[1]].sort_values(ascending = False).index[1]\n",
    "    val3 = corr.loc[three_crimes[2]].sort_values(ascending = False).index[1]\n",
    "    \n",
    "    most_corr = set()   #make set to store the 2 most correlated columns in bc a set will remove duplicates\n",
    "    most_corr.add(val1) \n",
    "    most_corr.add(val2)\n",
    "    most_corr.add(val3)\n",
    "    corr_most = list(most_corr) #turn into list bc easier to work with\n",
    "    \n",
    "    #figure out which crime has greater max value:\n",
    "    all_maxs = criminy1.max()   #get max of every column\n",
    "    #get max of the 2 columns in corr_most list, take their argmax to find which one is max and then access\n",
    "    #corr_most list at that index to get the column want\n",
    "    ans_1 = corr_most[np.argmax([all_maxs[corr_most[0]], all_maxs[corr_most[1]]])]\n",
    "  \n",
    "    #part 2:\n",
    "    criminy2 = criminy.iloc[40:] #want data starting at 2000 (years are index = row) so use iloc\n",
    "    criminy2 = criminy2.sort_values('Murder') #sort data in ascending order according to murders\n",
    "    mask2 = criminy2['Aggravated Assault'] > 850000  #make mask to get years want\n",
    "    ans_2 = criminy2[mask2].index.values #save indices (the row labels, years) and turn into array\n",
    "    \n",
    "    #part 3:\n",
    "    crime_rate = criminy['Total'] / criminy['Population']  #first get the crime rate which is total crime/pop\n",
    "    highest_year_index = np.argmax(crime_rate)           #want year w/ highest crime rate and years are the indices, so use argmax here\n",
    "    row = criminy.iloc[highest_year_index]               #get the actual year w/ highest crime rate                     \n",
    "    highest_crime = row.drop('Population').drop('Total').max() #need get rid of pop, total to get the highest crime for that year/row\n",
    "    \n",
    "    #get % of total crime that year (so at that row). drop pop, get max bc the total will be next highest after pop\n",
    "    ans_3 = highest_crime / row.drop('Population').max()\n",
    "    \n",
    "    return ans_1, ans_2, float(ans_3)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Property',\n",
       " array([2000, 2001, 2002, 2003, 2005, 2007, 2006]),\n",
       " 0.8997188308734142)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test prob 3\n",
    "prob3()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4pfN6PbxsgC3"
   },
   "source": [
    "# Problem 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TAavKLA17LsN"
   },
   "outputs": [],
   "source": [
    "def prob4(file='DJIA.csv'):\n",
    "    \"\"\"\n",
    "\n",
    "    Read the data with a DatetimeIndex as the index.\n",
    "    Drop rows any rows without numerical values, cast the \"VALUE\" column to floats, then return the updated DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "        file (str): data file\n",
    "    Returns:\n",
    "        df (DataFrame): updated DataFrame of stock market data\n",
    "    \"\"\"\n",
    "    dow = pd.read_csv(file, dtype = {'VALUE' : np.float64}, na_values = '.') #read dataframe in, cast VALUE cols to be floats\n",
    "                                                                             #turn everything not a number into a NaN so that can more easily drop them\n",
    "    dow.set_index(pd.to_datetime(dow[\"DATE\"]), inplace = True)               #make the index a DatetimeIndex\n",
    "    \n",
    "    dow = dow.dropna() #drop any rows w/out numerical values\n",
    "    \n",
    "    dow = dow.drop(columns = 'DATE') #need delete one of the date columns\n",
    "    \n",
    "    return dow\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VALUE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DATE</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2006-09-27</th>\n",
       "      <td>11689.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-09-28</th>\n",
       "      <td>11718.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-09-29</th>\n",
       "      <td>11679.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-10-02</th>\n",
       "      <td>11670.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-10-03</th>\n",
       "      <td>11727.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-09-20</th>\n",
       "      <td>18129.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-09-21</th>\n",
       "      <td>18293.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-09-22</th>\n",
       "      <td>18392.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-09-23</th>\n",
       "      <td>18261.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-09-26</th>\n",
       "      <td>18094.83</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2517 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               VALUE\n",
       "DATE                \n",
       "2006-09-27  11689.24\n",
       "2006-09-28  11718.45\n",
       "2006-09-29  11679.07\n",
       "2006-10-02  11670.35\n",
       "2006-10-03  11727.34\n",
       "...              ...\n",
       "2016-09-20  18129.96\n",
       "2016-09-21  18293.70\n",
       "2016-09-22  18392.46\n",
       "2016-09-23  18261.45\n",
       "2016-09-26  18094.83\n",
       "\n",
       "[2517 rows x 1 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob4()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I663KesNsjMK"
   },
   "source": [
    "# Problem 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob5(file='paychecks.csv'):\n",
    "    \"\"\"\n",
    "\n",
    "    Create data_range for index of paycheck data.\n",
    "\n",
    "    Parameters:\n",
    "        file (str): data file\n",
    "    Returns:\n",
    "        df (DataFrame): DataFrame of paycheck data\n",
    "    \"\"\"\n",
    "    paychecks = pd.read_csv(file, names = ['Pay']) #need create names bc otherwise the formatting is off\n",
    "    dates = pd.date_range(start = '3/14/2008', periods = 93, freq = '2W-FRI') #get the dates w/ pd.date_range()\n",
    "                                                                              #need specify the frequency bc only paychecks to be given out every other Friday\n",
    "    paychecks = paychecks.set_index(dates) #set the dates as the new index of the DataFrame\n",
    "    \n",
    "    return paychecks\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2008-03-14</th>\n",
       "      <td>1122.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-03-28</th>\n",
       "      <td>921.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-04-11</th>\n",
       "      <td>962.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-04-25</th>\n",
       "      <td>1035.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-05-09</th>\n",
       "      <td>1078.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-07-29</th>\n",
       "      <td>1095.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-08-12</th>\n",
       "      <td>1018.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-08-26</th>\n",
       "      <td>1027.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-09-09</th>\n",
       "      <td>1005.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-09-23</th>\n",
       "      <td>963.29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>93 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Pay\n",
       "2008-03-14  1122.26\n",
       "2008-03-28   921.03\n",
       "2008-04-11   962.46\n",
       "2008-04-25  1035.97\n",
       "2008-05-09  1078.59\n",
       "...             ...\n",
       "2011-07-29  1095.53\n",
       "2011-08-12  1018.39\n",
       "2011-08-26  1027.08\n",
       "2011-09-09  1005.90\n",
       "2011-09-23   963.29\n",
       "\n",
       "[93 rows x 1 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob5()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I663KesNsjMK"
   },
   "source": [
    "# Problem 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KGxh0mpSDLDD"
   },
   "outputs": [],
   "source": [
    "def prob6(file='DJIA.csv'):\n",
    "    \"\"\"\n",
    "    Compute the following information about the DJIA dataset\n",
    "    1. The single day with the largest gain\n",
    "    2. The single day with the largest loss\n",
    "\n",
    "    Parameters:\n",
    "        file (str): data file\n",
    "    Returns:\n",
    "        max_day (<M8[ns]): DateTimeIndex of maximum change\n",
    "        min_day (<M8[ns]): DateTimeIndex of minimum change\n",
    "    \"\"\"\n",
    "    djia = prob4(file) #callthe DJIA dataset from prob 4 that has data time index\n",
    "    \n",
    "    #get the day w/ largest gain: so need shift through all the days, find the difference in the values btw the days\n",
    "    diffs = djia - djia.shift(1)  #find changes from one day to the next. this gives array that can find the gains, losses from\n",
    "    \n",
    "    gains_baby = diffs.idxmax()    #get index of the largest gain\n",
    "    loss_boo_hoo = diffs.idxmin()  #get index of the largest loss\n",
    "        \n",
    "    return gains_baby, loss_boo_hoo\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(VALUE   2008-10-13\n",
       " dtype: datetime64[ns],\n",
       " VALUE   2008-09-29\n",
       " dtype: datetime64[ns])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob6()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "pandas1.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
