{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science Essentials: Data Cleaning\n",
    "    Jane Slagle\n",
    "    Vol 3 lab bebe\n",
    "    10/6/22\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1\n",
    "\n",
    "The g\\_t\\_results.csv file is a set of parent-reported scores on their child's Gifted and Talented tests. \n",
    "The two tests, OLSAT and NNAT, are used by NYC to determine if children are qualified for gifted programs.\n",
    "The OLSAT Verbal has 16 questions for Kindergardeners and 30 questions for first, second, and third graders.\n",
    "The NNAT has 48 questions. \n",
    "Using this dataset, answer the following questions.\n",
    "\n",
    "\n",
    "1) What column has the highest number of null values and what percent of its values are null? Print the answer as a tuple with (column name, percentage). Make sure the second value is a percent.\n",
    "\n",
    "2) List the columns that should be numeric that aren't. Print the answer as a tuple.\n",
    "\n",
    "3) How many third graders have scores outside the valid range for the OLSAT Verbal Score? Print the answer\n",
    "\n",
    "4) How many data values are missing (NaN)? Print the number.\n",
    "\n",
    "Each part is one point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('School Assigned', 75.21367521367522)\n",
      "('OSLAT Verbal Score', 'OSLAT Verbal Percentile', 'NNAT Non Verbal Raw Score')\n",
      "1\n",
      "192\n"
     ]
    }
   ],
   "source": [
    "tests_df = pd.read_csv(\"g_t_results.csv\")  #read in the data\n",
    "\n",
    "#Question 1: want column w/ highest number of null values\n",
    "\n",
    "num_null = tests_df.isna().sum()  #count number of nan values in each column\n",
    "#print(num_null) #from this: see that School Assigned column has highest number of null values\n",
    "\n",
    "#want % of values in School Assigned column that are null:\n",
    "total_values = len(tests_df[\"School Assigned\"])  #first get the total number of values have in that column\n",
    "num_null_want = tests_df['School Assigned'].isna().sum()  #then get the numver of null values in that column specifically\n",
    "\n",
    "percent_null = (num_null_want / total_values)*100 #calculate the actual % now\n",
    "print(('School Assigned', percent_null))\n",
    "\n",
    "#Question 2: list columns that should be numeric but aren't\n",
    "\n",
    "#print(tests_df.dtypes) #get datatype of each column\n",
    "print(('OSLAT Verbal Score', 'OSLAT Verbal Percentile', 'NNAT Non Verbal Raw Score')) #all of these columns all numeric values, but have object datatype\n",
    "\n",
    "#Question 3: How many 3rd graders have scores outside valid range for OSLAT verbal score?\n",
    "third_graders_man = tests_df[tests_df[\"Entering Grade Level\"] == \"3\"] #want to only look at the 3rd graders\n",
    "#print(third_graders_man) #valid range is 1 pt per question and there are 30 ?s\n",
    "print(1) #from looking at the 3rd \n",
    "\n",
    "#Question 4: how many data values are missing NaN?\n",
    "print(num_null.sum()) #doing .sum() counts the number of missing data pts in each column, but num_null already\n",
    "                      #has the sum of every column, so doing .sum() on that will get the TOTAL number of data\n",
    "                      #values that are missing NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2\n",
    "\n",
    "imdb.csv contains a small set of information about 99 movies. Clean the data set by doing the following in order: \n",
    "\n",
    "1) Remove duplicate rows by dropping the first **or** last. Print the shape of the dataframe after removing the rows.\n",
    "\n",
    "2) Drop all rows that contain missing data. Print the shape of the dataframe after removing the rows.\n",
    "\n",
    "3) Remove rows that have data outside valid data ranges and explain briefly how you determined your ranges for each column.\n",
    "\n",
    "4) Identify and drop columns with three or fewer different values. Print a tuple with the names of the columns dropped.\n",
    "\n",
    "5) Convert the titles to all lower case.\n",
    "\n",
    "Print the first five rows of your dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUESTION 1:\n",
      "(93, 13)\n",
      "\n",
      "QUESTION 2:\n",
      "(64, 13)\n",
      "\n",
      "QUESTION 3:\n",
      "(61, 13)\n",
      "To determine the ranges for each column, I decided that:\n",
      "1) It did not make sense to have a negative amount of time (for no amount of time) for the duration of a movie\n",
      "2) It did not make sense to have a negative gross for a movie, but it did make sense to have no gross at all for a movie\n",
      "3) It did not make sense to have a movie come out before the year that the first ever movie came out\n",
      "4) It did not make sense to have a negative budget or no budget at all for a movie\n",
      "5) It did not make sense to have a negative amount of facebook likes, but it did make sense to have no facebook likes for a movie if there was no facebook post for it or if people hated the movie\n",
      "\n",
      "QUESTION 4:\n",
      "('color', 'language')\n",
      "\n",
      "QUESTION 5:\n",
      "       director_name  duration        gross  \\\n",
      "0    Martin Scorsese       240  116866727.0   \n",
      "1        Shane Black       195  408992272.0   \n",
      "2  Quentin Tarantino       187   54116191.0   \n",
      "3   Kenneth Lonergan       186      46495.0   \n",
      "4      Peter Jackson       186  258355354.0   \n",
      "\n",
      "                                 genres                          movie_title  \\\n",
      "0          Biography|Comedy|Crime|Drama              the wolf of wall street   \n",
      "1               Action|Adventure|Sci-Fi                           iron man 3   \n",
      "2  Crime|Drama|Mystery|Thriller|Western                    the hateful eight   \n",
      "3                                 Drama                             margaret   \n",
      "4                     Adventure|Fantasy  the hobbit: the desolation of smaug   \n",
      "\n",
      "   title_year country       budget  imdb_score  \\\n",
      "0        2013     USA  100000000.0         8.2   \n",
      "1        2013     USA  200000000.0         7.2   \n",
      "2        2015     USA   44000000.0         7.9   \n",
      "3        2011     usa   14000000.0         6.5   \n",
      "4        2013     USA  225000000.0         7.9   \n",
      "\n",
      "                                              actors  movie_facebook_likes  \n",
      "0  Leonardo DiCaprio,Matthew McConaughey,Jon Favreau                138000  \n",
      "1          Robert Downey Jr.,Jon Favreau,Don Cheadle                 95000  \n",
      "2          Craig Stark,Jennifer Jason Leigh,ZoÃ« Bell                114000  \n",
      "3        Matt Damon,Kieran Culkin,John Gallagher Jr.                     0  \n",
      "4              Aidan Turner,Adam Brown,James Nesbitt                 83000  \n"
     ]
    }
   ],
   "source": [
    "movie_df = pd.read_csv(\"imdb.csv\")  #read in the data\n",
    "\n",
    "#part 1: remove duplicate rows by dropping first OR last\n",
    "movie_df.drop_duplicates(inplace = True) #keep = first says to only keep the first instances\n",
    "print(\"QUESTION 1:\")\n",
    "print(movie_df.shape)\n",
    "print(\"\")\n",
    "\n",
    "#part 2: drop all rows that contain missing data\n",
    "movie_df = movie_df.dropna() #drop all rows w/ NaN, which is missing data\n",
    "print(\"QUESTION 2:\")\n",
    "print(movie_df.shape)\n",
    "print(\"\")\n",
    "\n",
    "#part 3: remove rows that have data outside valid data ranges\n",
    "movie_df = movie_df[movie_df[\"duration\"] >= 0]             #doesn't make sense to have negative time for a movie\n",
    "movie_df = movie_df[movie_df[\"gross\"] > 0]                #doesn't make sense to have negative gross\n",
    "movie_df = movie_df[movie_df[\"title_year\"] >= 1888]       #doesn't make sense to have a movie before the 1st ever movie came out\n",
    "movie_df = movie_df[movie_df[\"budget\"] >= 0]               #doesn't make sense to have a negative budget\n",
    "movie_df = movie_df[movie_df[\"imdb_score\"] > 0 ]          #doesn't make sense to have a negative score\n",
    "movie_df = movie_df[movie_df[\"movie_facebook_likes\"] >= 0] #doesn't make sense to have negative facebook likes\n",
    "\n",
    "print(\"QUESTION 3:\")\n",
    "print(movie_df.shape)\n",
    "#explain briefly how you determined your ranges for each column:\n",
    "print(\"To determine the ranges for each column, I decided that:\")\n",
    "print(\"1) It did not make sense to have a negative amount of time (for no amount of time) for the duration of a movie\")\n",
    "print(\"2) It did not make sense to have a negative gross for a movie, but it did make sense to have no gross at all for a movie\")\n",
    "print(\"3) It did not make sense to have a movie come out before the year that the first ever movie came out\")\n",
    "print(\"4) It did not make sense to have a negative budget or no budget at all for a movie\")\n",
    "print(\"5) It did not make sense to have a negative amount of facebook likes, but it did make sense to have no facebook likes for a movie if there was no facebook post for it or if people hated the movie\")\n",
    "print(\"\")\n",
    "\n",
    "#part 4: identify, drop columns w/ 3 or fewer different values\n",
    "unique = movie_df.nunique() #nunique() counts # of unique values in each row and we want find columns w/ 3 or fewer unique values\n",
    "#print(unique) #print out to see how many unique values each column in dataframe has\n",
    "movie_df = movie_df.drop(['color', 'language'], axis = 1) #drop those columns that have 3 or fewer diff values\n",
    "print(\"QUESTION 4:\")\n",
    "print((\"color\", \"language\"))\n",
    "print(\"\")\n",
    "\n",
    "#part 5: convert the titles to all lower case\n",
    "movie_df['movie_title'] = movie_df['movie_title'].str.lower() #have 'movie_title' column. str.lower() converts all to lowercase\n",
    "\n",
    "#print the 1st 5 rows of your dataframe:\n",
    "print(\"QUESTION 5:\")\n",
    "print(movie_df.head(5)) #head(N) will print the 1st 5 rows of dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3\n",
    "\n",
    "basketball.csv contains data for all NBA players between 2001 and 2018.\n",
    "Each row represents a player's stats for a year.\n",
    "\n",
    "Create two new features:\n",
    "\n",
    "    career_length (int): number of years player has been playing (start at 0).\n",
    "    \n",
    "    target (str): The target team if the player is leaving. If the player is retiring, the target should be 'retires'.\n",
    "                  A player is retiring if their name doesn't exist the next year.\n",
    "                  (Set the players in 2019 to NaN).\n",
    "\n",
    "Remove all duplicate players in each year.\n",
    "Remove all rows except those where a player changes team, that is, target is not null nor 'retires'.\n",
    "\n",
    "Drop the player, year, and team_id columns.\n",
    "\n",
    "Return the first 10 lines of your dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6454/851386723.py:16: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  nextyrInfo = [bball_df[bball_df['player'] == player][bball_df['year']==year+1]['team_id'] for player, year in zip(bball_df['player'], bball_df['year'])]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>per</th>\n",
       "      <th>ws</th>\n",
       "      <th>bpm</th>\n",
       "      <th>career_length</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>27</td>\n",
       "      <td>8.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.5</td>\n",
       "      <td>7</td>\n",
       "      <td>PHO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>24</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>4</td>\n",
       "      <td>ATL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>24</td>\n",
       "      <td>15.9</td>\n",
       "      <td>6.2</td>\n",
       "      <td>2.9</td>\n",
       "      <td>5</td>\n",
       "      <td>MEM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>33</td>\n",
       "      <td>12.7</td>\n",
       "      <td>3.7</td>\n",
       "      <td>-1.9</td>\n",
       "      <td>16</td>\n",
       "      <td>HOU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>32</td>\n",
       "      <td>11.8</td>\n",
       "      <td>5.3</td>\n",
       "      <td>0.7</td>\n",
       "      <td>15</td>\n",
       "      <td>PHO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>29</td>\n",
       "      <td>7.5</td>\n",
       "      <td>1.1</td>\n",
       "      <td>-2.8</td>\n",
       "      <td>11</td>\n",
       "      <td>MIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>31</td>\n",
       "      <td>14.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>12</td>\n",
       "      <td>SAS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>25</td>\n",
       "      <td>14.1</td>\n",
       "      <td>2.9</td>\n",
       "      <td>-2.4</td>\n",
       "      <td>8</td>\n",
       "      <td>CHO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>29</td>\n",
       "      <td>12.6</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>SAC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>28</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.2</td>\n",
       "      <td>9</td>\n",
       "      <td>MIL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     age   per   ws  bpm  career_length target\n",
       "453   27   8.2  1.0 -2.5              7    PHO\n",
       "461   24  13.0  1.2 -0.9              4    ATL\n",
       "462   24  15.9  6.2  2.9              5    MEM\n",
       "464   33  12.7  3.7 -1.9             16    HOU\n",
       "467   32  11.8  5.3  0.7             15    PHO\n",
       "477   29   7.5  1.1 -2.8             11    MIN\n",
       "482   31  14.1  1.9 -0.2             12    SAS\n",
       "489   25  14.1  2.9 -2.4              8    CHO\n",
       "490   29  12.6  2.8  0.1              4    SAC\n",
       "493   28  13.0  0.0 -3.2              9    MIL"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bball_df = pd.read_csv(\"basketball.csv\") #read in the file\n",
    "\n",
    "#remove all duplicates of a player in each year:\n",
    "bball_df.drop_duplicates(['player', 'year'], inplace = True) #need specify player, year to say get rid of all duplicates for those 2 columns combined \n",
    "\n",
    "#create new feature career_length:\n",
    "#want num yrs player has been playing: will be same as len of rows that that player shows up\n",
    "#make dict to get all of the players: key is player name, value is num times the player name shows up\n",
    "#when make dict: loop through the number of unique player names that have: so loop through each player\n",
    "players = {player: len(bball_df[bball_df['player'] == player]) for player in np.unique(bball_df['player'])}\n",
    "bball_df[\"career_length\"] = [players[player] for player in bball_df['player']] #create career_length column now\n",
    "\n",
    "#need see if player is there the next year for when make target column:\n",
    "#this loops through all of the players, years and sees if the player is there the next year, specify team_id\n",
    "#because want the target team (the team id) for the next year\n",
    "nextyrInfo = [bball_df[bball_df['player'] == player][bball_df['year']==year+1]['team_id'] for player, year in zip(bball_df['player'], bball_df['year'])]\n",
    "\n",
    "#now actually create target column:\n",
    "#if nextyrInfo thingy has length 0 (has nothing in it), then know they're retiring\n",
    "#else: case for when they're not retiring: np.unique(thingy)[0] just gives you the team id which is what we want\n",
    "bball_df['target'] = ['retires' if len(thingy) == 0 else np.unique(thingy)[0] for thingy in nextyrInfo]\n",
    "\n",
    "bball_df.loc[bball_df['year'] == 2019, 'target'] = np.nan #set all players in 2019 to have target NaN\n",
    "\n",
    "#remove all rows except those where target is NOT nan nor retires\n",
    "bball_df = bball_df[bball_df['target'] != bball_df['team_id']] #drop rows where player does not change team\n",
    "bball_df = bball_df[bball_df['year'] != 2019] #drop rows where all nan target entries bc 2019 is all nans\n",
    "bball_df = bball_df[bball_df['target'] != 'retires']  #drop rows where all retire target entries\n",
    "\n",
    "#drop the player, year, team_id columns:\n",
    "bball_df = bball_df.drop(['player', 'year', 'team_id'], axis = 1)\n",
    "\n",
    "#return 1st 10 lines of dataframe:\n",
    "display(bball_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4\n",
    "\n",
    "Load housing.csv into a dataframe with index=0. Descriptions of the features are in housing_data_description.txt.  \n",
    "The goal is to construct a regression model that predicts SalePrice using the other features of the dataset.  Do this as follows:\n",
    "\n",
    "\t1) Identify and handle the missing data.  Hint: Dropping every row with some missing data is not a good choice because it gives you an empty dataframe.  What can you do instead?\n",
    "    \n",
    "\t2) Identify the variable with nonnumeric values that are misencoded as numbers.  One-hot encode it. Hint: don't forget to remove one of the encoded columns to prevent collinearity with the constant column (which you will add later).\n",
    "    \n",
    "    3) Add a constant column to the dataframe.\n",
    "\n",
    "    4) Save a copy of the dataframe.\n",
    "\n",
    "\t5) Choose four categorical featrues that seem very important in predicting SalePrice. One-hot encode these features and remove all other categorical features.\n",
    "\t\t\n",
    "\t6) Run an OLS using all numerical data regression on your model.  \n",
    "\n",
    "\t\n",
    "Print the ten features that have the highest coef in your model and the summary. Don't print the OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "      <th>std err</th>\n",
       "      <th>t</th>\n",
       "      <th>P&gt;|t|</th>\n",
       "      <th>[0.025</th>\n",
       "      <th>0.975]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LotShape_IR2</th>\n",
       "      <td>24360.0</td>\n",
       "      <td>216000.000</td>\n",
       "      <td>0.113</td>\n",
       "      <td>0.910</td>\n",
       "      <td>-399000.000</td>\n",
       "      <td>447000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSSubClass_30</th>\n",
       "      <td>17750.0</td>\n",
       "      <td>10500.000</td>\n",
       "      <td>1.687</td>\n",
       "      <td>0.092</td>\n",
       "      <td>-2886.447</td>\n",
       "      <td>38400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OverallQual</th>\n",
       "      <td>17720.0</td>\n",
       "      <td>1309.768</td>\n",
       "      <td>13.533</td>\n",
       "      <td>0.000</td>\n",
       "      <td>15200.000</td>\n",
       "      <td>20300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Street_Pave</th>\n",
       "      <td>17580.0</td>\n",
       "      <td>431000.000</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.967</td>\n",
       "      <td>-827000.000</td>\n",
       "      <td>862000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LandContour_HLS</th>\n",
       "      <td>17410.0</td>\n",
       "      <td>215000.000</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.936</td>\n",
       "      <td>-405000.000</td>\n",
       "      <td>440000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSZoning_FV</th>\n",
       "      <td>15210.0</td>\n",
       "      <td>173000.000</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.930</td>\n",
       "      <td>-323000.000</td>\n",
       "      <td>354000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageCars</th>\n",
       "      <td>14500.0</td>\n",
       "      <td>3060.638</td>\n",
       "      <td>4.737</td>\n",
       "      <td>0.000</td>\n",
       "      <td>8494.538</td>\n",
       "      <td>20500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LotShape_IR1</th>\n",
       "      <td>13660.0</td>\n",
       "      <td>215000.000</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.949</td>\n",
       "      <td>-409000.000</td>\n",
       "      <td>436000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSSubClassConst</th>\n",
       "      <td>12120.0</td>\n",
       "      <td>432000.000</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.978</td>\n",
       "      <td>-834000.000</td>\n",
       "      <td>859000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LotShape_Reg</th>\n",
       "      <td>12020.0</td>\n",
       "      <td>215000.000</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.956</td>\n",
       "      <td>-411000.000</td>\n",
       "      <td>435000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    coef     std err       t  P>|t|      [0.025    0.975]\n",
       "LotShape_IR2     24360.0  216000.000   0.113  0.910 -399000.000  447000.0\n",
       "MSSubClass_30    17750.0   10500.000   1.687  0.092   -2886.447   38400.0\n",
       "OverallQual      17720.0    1309.768  13.533  0.000   15200.000   20300.0\n",
       "Street_Pave      17580.0  431000.000   0.041  0.967 -827000.000  862000.0\n",
       "LandContour_HLS  17410.0  215000.000   0.081  0.936 -405000.000  440000.0\n",
       "MSZoning_FV      15210.0  173000.000   0.088  0.930 -323000.000  354000.0\n",
       "GarageCars       14500.0    3060.638   4.737  0.000    8494.538   20500.0\n",
       "LotShape_IR1     13660.0  215000.000   0.063  0.949 -409000.000  436000.0\n",
       "MSSubClassConst  12120.0  432000.000   0.028  0.978 -834000.000  859000.0\n",
       "LotShape_Reg     12020.0  215000.000   0.056  0.956 -411000.000  435000.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_df = pd.read_csv(\"housing.csv\", index_col = 0) #load file in w/ index=0\n",
    "n = len(housing_df)\n",
    "\n",
    "#PART 1:\n",
    "#identify, handle missing data: missing data is NaNs, means we want to drop all nan values\n",
    "nan_percs = [len(housing_df[housing_df[c].isnull()])/n for c in housing_df.columns] #get % of nan entries\n",
    "mask = np.array(nan_percs) > 0.1  #create mask of which nan entries are greater than .01 (want drop these ones) bc want dorp those ones\n",
    "drop_it_low = housing_df.columns[mask]    #apply mask to columns of dataframe so know which columns to drop\n",
    "housing_df = housing_df.drop(drop_it_low, axis = 1) #now actually drop those columns\n",
    "housing_df = housing_df.dropna()  #now drop all rows with nans\n",
    "\n",
    "#PART 2:\n",
    "#the variable w/ non-numeric values that are misencoded as numbers is the column MSSubClass: bc they shld just\n",
    "#be descriptions of the neighborhoods (strings), but they're encoded as numbers SO know it's that one\n",
    "housing_df = pd.get_dummies(housing_df, columns = ['MSSubClass'])  #one hot encode it\n",
    "\n",
    "#once have one hot encoding: construct new feature for every possible value of the feature just one hot encoded \n",
    "#(these features are the bunch of new columns that get from the column just one hot encoded)\n",
    "MSSubCols = ['MSSubClass_20', 'MSSubClass_30', 'MSSubClass_40', 'MSSubClass_40', 'MSSubClass_45', 'MSSubClass_50',\n",
    "            'MSSubClass_60', 'MSSubClass_70', 'MSSubClass_75', 'MSSubClass_80', 'MSSubClass_85', 'MSSubClass_90',\n",
    "            'MSSubClass_120', 'MSSubClass_160', 'MSSubClass_180', 'MSSubClass_190']\n",
    "\n",
    "#PART 3: summing the one hot encoding terms gives constant column want add to df:\n",
    "housing_df['MSSubClassConst'] = np.sum(housing_df[MSSubCols].to_numpy(), axis = 1)\n",
    "\n",
    "#want drop one of the encoded columns to prevent blah blah blah it says why in the problem:\n",
    "housing_df = housing_df.drop(columns = 'MSSubClass_190')\n",
    "\n",
    "#PART 4: save copy of dataframe\n",
    "newhousing_df = housing_df.copy()\n",
    "\n",
    "#PART 5: choose 4 cateogrical features = OBJECT data types:\n",
    "important_fts = ['MSZoning', 'Street', 'LotShape', 'LandContour']\n",
    "#print(housing_df.dtypes[housing_df.dtypes == object].index) #this will print out all categorical objects have\n",
    "\n",
    "#one hot encode these important features:\n",
    "housing_df = pd.get_dummies(housing_df, columns = important_fts)\n",
    "\n",
    "#remove all of the other categorical features:\n",
    "dropCols = ['Utilities','LotConfig', 'LandSlope', 'Neighborhood', 'Condition1', 'Condition2',\n",
    "       'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'Exterior1st',\n",
    "       'Exterior2nd', 'MasVnrType', 'ExterQual', 'ExterCond', 'Foundation',\n",
    "       'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2',\n",
    "       'Heating', 'HeatingQC', 'CentralAir', 'Electrical', 'KitchenQual',\n",
    "       'Functional', 'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond',\n",
    "       'PavedDrive', 'SaleType', 'SaleCondition']\n",
    "\n",
    "housing_df = housing_df.drop(columns = dropCols) #now actually drop them WOOHOO!\n",
    "\n",
    "#PART 6: run OLS regression\n",
    "#want predict sale price so X in code given is sale price\n",
    "X = housing_df.drop(columns = ['SalePrice']) #drop sale price bc dont want use sale price to predict sale price\n",
    "y = housing_df['SalePrice']\n",
    "\n",
    "results = sm.OLS(y, X).fit() #run the OLS regression\n",
    "\n",
    "#convert summary table to dataframe:\n",
    "results_as_html = results.summary().tables[1].as_html()\n",
    "result_df = pd.read_html(results_as_html, header=0, index_col=0)[0]\n",
    "\n",
    "#print ten features w/ highest coeff in your model and summary: the summary has a coeff column\n",
    "result_df = result_df.sort_values(['coef'], ascending = False) #sort summary in descending order\n",
    "result_df.head(10)  #the 1st 10 features now are the ones w/ highest coeffs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 5\n",
    "\n",
    "Using the copy of the dataframe you created in Problem 4, one-hot encode all the categorical variables.\n",
    "Print the shape of the dataframe and run OLS.\n",
    "\n",
    "Print the ten features that have the highest coef in your model and the summary.\n",
    "Write a couple of sentences discussing which model is better and why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1338, 279)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "      <th>std err</th>\n",
       "      <th>t</th>\n",
       "      <th>P&gt;|t|</th>\n",
       "      <th>[0.025</th>\n",
       "      <th>0.975]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RoofMatl_Membran</th>\n",
       "      <td>149100.0</td>\n",
       "      <td>32200.0</td>\n",
       "      <td>4.626</td>\n",
       "      <td>0.000</td>\n",
       "      <td>85900.000</td>\n",
       "      <td>212000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RoofMatl_Metal</th>\n",
       "      <td>124300.0</td>\n",
       "      <td>31000.0</td>\n",
       "      <td>4.007</td>\n",
       "      <td>0.000</td>\n",
       "      <td>63400.000</td>\n",
       "      <td>185000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RoofMatl_WdShngl</th>\n",
       "      <td>100100.0</td>\n",
       "      <td>21000.0</td>\n",
       "      <td>4.763</td>\n",
       "      <td>0.000</td>\n",
       "      <td>58900.000</td>\n",
       "      <td>141000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageQual_Ex</th>\n",
       "      <td>85660.0</td>\n",
       "      <td>36300.0</td>\n",
       "      <td>2.361</td>\n",
       "      <td>0.018</td>\n",
       "      <td>14500.000</td>\n",
       "      <td>157000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Condition2_PosA</th>\n",
       "      <td>79330.0</td>\n",
       "      <td>38700.0</td>\n",
       "      <td>2.048</td>\n",
       "      <td>0.041</td>\n",
       "      <td>3330.600</td>\n",
       "      <td>155000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RoofStyle_Shed</th>\n",
       "      <td>65090.0</td>\n",
       "      <td>35800.0</td>\n",
       "      <td>1.816</td>\n",
       "      <td>0.070</td>\n",
       "      <td>-5230.185</td>\n",
       "      <td>135000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RoofMatl_Tar&amp;Grv</th>\n",
       "      <td>56560.0</td>\n",
       "      <td>22100.0</td>\n",
       "      <td>2.565</td>\n",
       "      <td>0.010</td>\n",
       "      <td>13300.000</td>\n",
       "      <td>99800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RoofMatl_Roll</th>\n",
       "      <td>51550.0</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>1.716</td>\n",
       "      <td>0.086</td>\n",
       "      <td>-7393.659</td>\n",
       "      <td>111000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RoofMatl_CompShg</th>\n",
       "      <td>47900.0</td>\n",
       "      <td>18900.0</td>\n",
       "      <td>2.532</td>\n",
       "      <td>0.011</td>\n",
       "      <td>10800.000</td>\n",
       "      <td>85000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Condition2_Artery</th>\n",
       "      <td>39250.0</td>\n",
       "      <td>30300.0</td>\n",
       "      <td>1.297</td>\n",
       "      <td>0.195</td>\n",
       "      <td>-20100.000</td>\n",
       "      <td>98600.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       coef  std err      t  P>|t|     [0.025    0.975]\n",
       "RoofMatl_Membran   149100.0  32200.0  4.626  0.000  85900.000  212000.0\n",
       "RoofMatl_Metal     124300.0  31000.0  4.007  0.000  63400.000  185000.0\n",
       "RoofMatl_WdShngl   100100.0  21000.0  4.763  0.000  58900.000  141000.0\n",
       "GarageQual_Ex       85660.0  36300.0  2.361  0.018  14500.000  157000.0\n",
       "Condition2_PosA     79330.0  38700.0  2.048  0.041   3330.600  155000.0\n",
       "RoofStyle_Shed      65090.0  35800.0  1.816  0.070  -5230.185  135000.0\n",
       "RoofMatl_Tar&Grv    56560.0  22100.0  2.565  0.010  13300.000   99800.0\n",
       "RoofMatl_Roll       51550.0  30000.0  1.716  0.086  -7393.659  111000.0\n",
       "RoofMatl_CompShg    47900.0  18900.0  2.532  0.011  10800.000   85000.0\n",
       "Condition2_Artery   39250.0  30300.0  1.297  0.195 -20100.000   98600.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The model from problem 4 is better BECAUSE the highest coefficients from the problem 4 model are a \n",
      "lot better than the ones here in problem 5. The highest coefficients in problem 4 give more important\n",
      "features for determining sale price than in problem 5. For example, features such as lot shape,\n",
      "overall quality, street pavement, garages, lot shapes, etc. (the features from problem 4)\n",
      "are much more important features for determining sale price than roofing materials, garage quality, etc.\n",
      "(the most important features from problem 5)\n"
     ]
    }
   ],
   "source": [
    "#use copy of dataframe from prob 4: one hot encode ALL the cateogrical variables\n",
    "newhousing_df = pd.get_dummies(newhousing_df, columns = newhousing_df.dtypes[newhousing_df.dtypes == object].index)\n",
    "print(newhousing_df.shape)\n",
    "\n",
    "#run OLS:\n",
    "X = newhousing_df.drop(columns = ['SalePrice'])\n",
    "y = newhousing_df['SalePrice']\n",
    "\n",
    "results = sm.OLS(y, X).fit()\n",
    "\n",
    "#print 10 features w/ highest coeffs in model, summary\n",
    "results_as_html = results.summary().tables[1].as_html()\n",
    "results_df = pd.read_html(results_as_html, header=0, index_col=0)[0]\n",
    "\n",
    "results_df = results_df.sort_values(['coef'], ascending = False)\n",
    "display(results_df.head(10))\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "#looking at the highest coeffs tells you which model is better: the highest coeffs are the ones that are\n",
    "#most important, so look at which ones are deemed more important to see which model is better\n",
    "print(\"The model from problem 4 is better BECAUSE the highest coefficients from the problem 4 model are a \")\n",
    "print(\"lot better than the ones here in problem 5. The highest coefficients in problem 4 give more important\")\n",
    "print(\"features for determining sale price than in problem 5. For example, features such as lot shape,\")\n",
    "print(\"overall quality, street pavement, garages, lot shapes, etc. (the features from problem 4)\")\n",
    "print(\"are much more important features for determining sale price than roofing materials, garage quality, etc.\")\n",
    "print(\"(the most important features from problem 5)\")\n",
    "\n",
    "#looking at highest coeffs tells you which model is better: the highest ones here w/ this model are not \n",
    "#    important for determining sale price "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
